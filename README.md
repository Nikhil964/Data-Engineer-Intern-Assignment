# Data-Engineer-Intern-Assignment

## Prerequisites
You will need a Python toolchain to run this

## About the repo
* It includes a 'scraper.py' and 'finalDataset.csv' files
* The 'scraper.py' a python code to scrape the wikipedia page and cleaning, storing the collected data in a csv file.
* The 'finalDataset.csv' a csv file which is clean, formatted and ready to be uploaded to a BigQuery table for analysis.
